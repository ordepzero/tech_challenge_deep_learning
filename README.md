# PrevisÃ£o de PreÃ§o de AÃ§Ãµes com Deep Learning

Este projeto Ã© uma plataforma robusta para treinamento, otimizaÃ§Ã£o e deploy de modelos de Deep Learning (LSTM e MLP) voltados para a previsÃ£o de preÃ§os de aÃ§Ãµes. A arquitetura utiliza tecnologias de ponta para garantir escalabilidade, rastreabilidade e monitoramento em tempo real.

## ğŸš€ Tecnologias Utilizadas

*   **FastAPI**: Framework web moderno e de alto desempenho para a construÃ§Ã£o da API.
*   **Ray**: Plataforma de computaÃ§Ã£o distribuÃ­da usada para orquestrar treinamentos paralelos e busca de hiperparÃ¢metros (Ray Tune).
*   **PyTorch & Lightning**: Frameworks para construÃ§Ã£o e treinamento simplificado de redes neurais.
*   **MLflow**: Ferramenta para gerenciamento do ciclo de vida de machine learning (rastreamento de experimentos, registro de modelos e artefatos).
*   **Prometheus & Grafana**: Conjunto para coleta de mÃ©tricas e visualizaÃ§Ã£o de dashboards (incluindo mÃ©tricas do Ray e da API).
*   **yfinance**: Biblioteca para download de dados histÃ³ricos de aÃ§Ãµes.
*   **Docker & Docker Compose**: ContainerizaÃ§Ã£o total para facilitar o desenvolvimento e deploy.

---

## ğŸ—ï¸ Arquitetura e Fluxo de Dados Detalhado

O diagrama abaixo ilustra a interaÃ§Ã£o entre os containers, os serviÃ§os de monitoramento e os diretÃ³rios onde os artefatos sÃ£o gerados:

```mermaid
sequenceDiagram
    participant U as UsuÃ¡rio
    participant API as FastAPI (App Container)
    participant R as Ray Workers (Distributed)
    participant ML as MLflow (Tracking)
    participant FS as Sistema de Arquivos (Volumes Docker)
    participant P as Prometheus (Metrics)
    participant G as Grafana (Dashboards)

    rect rgb(240, 240, 240)
    Note over U, FS: Fluxo de Treinamento e OtimizaÃ§Ã£o
    U->>API: POST /model/train ou /model/tune
    API->>R: Despacha Ator Ray (Treinamento Paralelo)
    R->>FS: Salva Checkpoints (.ckpt) em ./checkpoints/
    R->>FS: Salva Telemetria em ./lightning_logs/
    R->>FS: Salva Trials de Busca em ./ray_results/
    R->>ML: Registra ParÃ¢metros e Modelo PyTorch em ./mlruns/
    API-->>U: Retorna Task ID (Status em Tempo Real)
    end

    rect rgb(235, 255, 235)
    Note over R, G: Monitoramento de Recursos e SaÃºde
    R->>P: Exporta MÃ©tricas de CPU/GPU (Ray Exporter)
    API->>P: Exporta LatÃªncia e Erros (FastAPI Instrumentator)
    P->>P: Agrega Dados via Coleta Ativa (Scraping)
    G->>P: Consulta mÃ©tricas (DataSource)
    G-->>U: Exibe Dashboards de Infra e Modelos
    end

    rect rgb(230, 245, 255)
    Note over U, ML: Fluxo de InferÃªncia (PrediÃ§Ã£o)
    U->>API: POST /model/predict
    API->>ML: Busca o melhor modelo em ./mlruns/
    ML-->>API: Carrega pesos (.pth) para MemÃ³ria (LOADED_MODELS)
    API-->>U: Retorna PrediÃ§Ã£o (PreÃ§o Real Denormalizado)
    end
```

---

## ğŸ“‚ Estrutura do Projeto

```text
.
â”œâ”€â”€ data/                  # Dados do yfinance (raw e processed)
â”œâ”€â”€ mlruns/                # [MLflow] Metadados e artefatos das execuÃ§Ãµes (runs)
â”œâ”€â”€ mlflow.db              # [MLflow] Banco de dados SQLite (se configurado backend DB)
â”œâ”€â”€ checkpoints/           # [Lightning] Salva os pesos (.ckpt) do melhor modelo durante o treino
â”œâ”€â”€ lightning_logs/        # [Lightning] Logs padrÃ£o e telemetria do PyTorch Lightning
â”œâ”€â”€ ray_results/           # [Ray Tune] Resultados, logs e checkpoints dos trials de tuning
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/               # Endpoints da aplicaÃ§Ã£o FastAPI
â”‚   â”œâ”€â”€ models/            # Arquiteturas de Redes Neurais (LSTM, MLP)
â”‚   â”œâ”€â”€ services/          # LÃ³gica de negÃ³cio (Pipeline, Tuning, Optimization)
â”‚   â”œâ”€â”€ schemas/           # Modelos Pydantic para validaÃ§Ã£o de API
â”‚   â””â”€â”€ registry/          # Registro de estados de tarefas (Ray Actors)
â”œâ”€â”€ grafana_dashboards_prov.yaml # [Grafana] ConfiguraÃ§Ã£o para carregar dashboards automaticamente
â”œâ”€â”€ grafana_datasource.yml # [Grafana] ConfiguraÃ§Ã£o da conexÃ£o com o Prometheus
â”œâ”€â”€ main.py                # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ docker-compose.yml     # OrquestraÃ§Ã£o de serviÃ§os (App, Prometheus, Grafana)
â””â”€â”€ Dockerfile             # DefiniÃ§Ã£o do container da aplicaÃ§Ã£o (com suporte a GPU)
```

---

## ğŸ” Detalhes dos Componentes Gerados

Muitos arquivos e diretÃ³rios sÃ£o criados automaticamente pelos frameworks utilizados:

*   **`checkpoints/`**: Criado pelo PyTorch Lightning (`ModelCheckpoint`). O `pipeline_service` instrui o Lightning a salvar aqui o estado da rede neural sempre que a perda de validaÃ§Ã£o (`val_loss`) atinge um novo mÃ­nimo. Ã‰ essencial para recuperar o modelo apÃ³s o treino.
*   **`mlruns/`**: Criado pelo MLflow. ContÃ©m pastas numeradas para cada experimento. Dentro de cada pasta, hÃ¡ metadados (parÃ¢metros, mÃ©tricas) e os modelos salvos em formato serializado. O `MLFlowManager` utiliza este diretÃ³rio para consultar e carregar modelos.
*   **`ray_results/`**: Criado pelo Ray Tune durante a execuÃ§Ã£o do `tuning_service`. Armazena o histÃ³rico de cada "trial" (amostra de hiperparÃ¢metro). Se um tuning for interrompido, o Ray pode usar esses arquivos para retomar de onde parou.
*   **`lightning_logs/`**: Logs operacionais do Lightning. Ãštil para depurar erros de baixo nÃ­vel na GPU ou problemas internos do PyTorch.
*   **`grafana_dashboards_prov.yaml` / `datasource.yml`**: Criados manualmente para configurar o ambiente. O Grafana lÃª esses arquivos ao iniciar para saber onde o Prometheus estÃ¡ e quais grÃ¡ficos de mÃ©tricas exibir automaticamente.

---

## âš™ï¸ Como Executar

### PrÃ©-requisitos
*   Docker e Docker Compose instalados.
*   (Opcional) NVIDIA Container Toolkit para suporte Ã  aceleraÃ§Ã£o por GPU.

### Passo a Passo

1.  **Subir os serviÃ§os**:
    ```bash
    docker-compose up --build
    ```

2.  **Acessar as interfaces**:
    *   **API (Swagger)**: [http://localhost:8000/docs](http://localhost:8000/docs)
    *   **Ray Dashboard**: [http://localhost:8265](http://localhost:8265)
    *   **MLflow (Rastreamento)**: [http://localhost:5000](http://localhost:5000)
    *   **Grafana**: [http://localhost:3000](http://localhost:3000) (Login padrÃ£o: `admin` / `admin`)
    *   **Prometheus**: [http://localhost:9090](http://localhost:9090)

---

## ğŸ“Š Fluxo de Dados e Treinamento

1.  **Coleta**: O endpoint `/data/download` utiliza a `StockDataLoader` para baixar CSVs via `yfinance`.
2.  **Processamento**: A classe `TimeSeriesDataModule` aplica a "Window Normalization" (normalizaÃ§Ã£o por janela) utilizando o Ãºltimo valor da janela como base. Isso foca a previsÃ£o no **retorno relativo** em vez do preÃ§o bruto, reduzindo vieses de tendÃªncia.
3.  **Treinamento**: O `pipeline_service` dispara um ator remoto do Ray que treina o modelo selecionado e salva o melhor checkpoint automaticamente no MLflow.
4.  **Tuning**: O `tuning_service` utiliza o Ray Tune com o algoritmo ASHA para disparar mÃºltiplos trials simultÃ¢neos, encontrando a melhor combinaÃ§Ã£o de hiperparÃ¢metros.

---

## ğŸ›£ï¸ Endpoints Principais (Exemplos)

### Treinamento (`/model/train`)
Exemplo de corpo da requisiÃ§Ã£o:
```json
{
  "model_type": "lstm",
  "hidden_dim": 64,
  "num_layers": 2,
  "dropout_prob": 0.2,
  "learning_rate": 0.001,
  "window_size": 60
}
```

### PrediÃ§Ã£o (`/model/predict`)
Realiza a previsÃ£o do prÃ³ximo preÃ§o. Se o `ticker` for fornecido e a lista de `data` estiver incompleta, o sistema busca automaticamente os dados histÃ³ricos para completar a janela necessÃ¡ria para o modelo.

### OtimizaÃ§Ã£o e Pruning (`/model/prune`)
Aplica a tÃ©cnica de "L1 Unstructured Pruning" para reduzir o tamanho do modelo, removendo conexÃµes neurais menos significativas, e registra uma nova versÃ£o do modelo no MLflow.

---

## ğŸ©º SaÃºde dos Experimentos

O que chamamos de "saÃºde dos experimentos" Ã© a capacidade de monitorar se o aprendizado do modelo Ã© eficaz e estÃ¡vel. Isso Ã© feito via:

1.  **Check de Overfitting**: Comparar a curva de `train_loss` com `val_loss` no MLflow. Se o erro de treino cair e o de validaÃ§Ã£o subir, o modelo estÃ¡ "decorando" os dados.
2.  **Gradientes SaudÃ¡veis**: Verificar se as perdas nÃ£o estÃ£o se tornando `NaN` (Not a Number), o que indicaria uma `learning_rate` muito alta ou falta de normalizaÃ§Ã£o.
3.  **UtilizaÃ§Ã£o de Recursos**: AtravÃ©s do Grafana/Prometheus, monitoramos se a GPU estÃ¡ sendo devidamente utilizada ou se hÃ¡ gargalo na CPU durante o processamento de dados do Ray.

---

## ğŸ“ˆ MLflow: Melhorando o Modelo e a Esteira

O Dashboard do MLflow permite uma anÃ¡lise profunda para evoluir o projeto:

### AtravÃ©s da Interface (UI)
*   **ComparaÃ§Ã£o**: Selecione mÃºltiplos "runs" de tuning e use o grÃ¡fico de **Coordenadas Paralelas** para visualizar qual combinaÃ§Ã£o de hiperparÃ¢metros resulta na menor perda.
*   **Reprodutibilidade**: Cada run registra a versÃ£o exata do cÃ³digo e os parÃ¢metros. VocÃª pode copiar a configuraÃ§Ã£o de um modelo vencedor e usÃ¡-la como base para treinamentos mais longos.

### AtravÃ©s da LÃ³gica (Pipeline)
*   **Pruning**: Use o endpoint `/model/prune` em modelos que performam bem mas sÃ£o pesados. O MLflow registrarÃ¡ a versÃ£o "podada", permitindo comparar a perda de acurÃ¡cia vs ganho de velocidade.
*   **EspecializaÃ§Ã£o (Finetuning)**: A esteira pode ser melhorada usando o MLflow para carregar pesos de uma aÃ§Ã£o (ex: AAPL) e especializÃ¡-la em outra (ex: MSFT), acelerando a convergÃªncia.
*   **Registro de Modelos**: VocÃª pode marcar modelos como "Production" ou "Staging" via UI, controlando qual versÃ£o a rota de prediÃ§Ã£o deve carregar.
